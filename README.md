# â˜€ï¸ Forecasting Solar Irradiance in Saudi Arabia using State-of-the-Art Time Series Models

## ðŸ“Œ Project Overview
This project aims to forecast **Global Horizontal Irradiance (GHI)** â€” a key measure of solar energy potential â€” across Saudi Arabian cities using both **classical time series models** and **state-of-the-art deep learning techniques**.

We explore:
- Exploratory data analysis of GHI patterns across time and regions
- Baseline forecasting models: **Linear Regression**, **Prophet**, **XGBoost**
- Advanced forecasting using Transformer-based architectures like **Autoformer**, **Informer**, and **FEDformer** from Hugging Face
- Model evaluation and comparison using MAE, RMSE, and SMAPE

The dataset includes multivariate weather features such as temperature, humidity, wind speed, and cloud cover to improve prediction accuracy.

---

## ðŸ‡¸ðŸ‡¦ Why This Matters for Saudi Vision 2030

Saudi Arabia is undergoing a transformative shift toward **renewable energy**, targeting **50% clean energy generation by 2030**. Solar power, in particular, plays a critical role in mega-projects like:
- **NEOM**
- **Sudair Solar PV Plant**
- **Sakaka Solar Power Project**

Accurate forecasting of solar irradiance is essential for:
- **Grid stability and energy storage planning**
- **Efficient operation of solar farms**
- **Smart city infrastructure** and dynamic pricing
- **Localized AI innovation**, a Vision 2030 strategic pillar

This project demonstrates how **machine learning** and **data science** can directly contribute to these goals by enabling smarter, more efficient renewable energy systems in the Kingdom.

---

## ðŸ§  Objectives
- Understand and predict the temporal dynamics of solar irradiance (GHI) in Saudi Arabia
- Compare baseline and advanced models for time series forecasting
- Build a reusable pipeline for real-time GHI prediction
- Highlight the role of AI in sustainable energy and national development

---

> ðŸ“Ž **Tools & Libraries:** Python, Pandas, Matplotlib, XGBoost, Prophet, Hugging Face Transformers, Autoformer/Informer, PyTorch, Scikit-learn, Streamlit (for optional deployment)

